{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "add_particDesc_and_IDs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgJXbcRtafbC",
        "colab_type": "code",
        "outputId": "e94b496c-199d-45f9-c24f-1adcdfcec234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we4DTHJcxK6K",
        "colab_type": "code",
        "outputId": "68201c59-3574-439d-c0b3-c17cf8de0f4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "import re\n",
        "from lxml import etree\n",
        "import html as html_\n",
        "!pip install titlecase\n",
        "from titlecase import titlecase\n",
        "!pip install googletrans\n",
        "from googletrans import Translator\n",
        "translator = Translator()\n",
        "import csv\n",
        "import json\n",
        "import datetime\n",
        "from xml.etree import ElementTree as ET\n",
        "from copy import deepcopy"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: titlecase in /usr/local/lib/python3.6/dist-packages (0.12.0)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.6/dist-packages (2.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from googletrans) (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->googletrans) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lvwQxjP0KcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define prefix\n",
        "prefix = '{http://www.w3.org/XML/1998/namespace}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zexvLg4nWidM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_xml(xml):\n",
        "    # replace soft hyphen by true hyphen\n",
        "    xml = re.sub(r'\\xad', '-', xml)\n",
        "\n",
        "    # add mising #\n",
        "    xml = re.sub(r'(<sp who=\"#spCarl) (spDoktorn\">)', r'\\1 #\\2', xml)\n",
        "\n",
        "    # replace \"<idno type=\"dracor\">swe000044</tei:idno>\" with \"<idno type=\"dracor\">swe000044</idno>\" (so that etree could parse the file)\n",
        "    xml = re.sub(r'(<idno type=\"dracor\">)([^<>]*?)</tei:idno>', r'\\1\\2</idno>', xml)\n",
        "    \n",
        "    return xml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCenaWoycCBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_root(xml):\n",
        "    parser = etree.XMLParser(remove_blank_text=True)  # remove_comments=True, remove_blank_text=True\n",
        "    root = etree.fromstring(xml, parser=parser)\n",
        "    return root"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwhF93xLTEVm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_particDesc_to_profileDesc(profileDesc):\n",
        "    # particDesc to profileDesc\n",
        "    particDesc = etree.Element('particDesc')\n",
        "    profileDesc.append(particDesc)\n",
        "    return particDesc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UlCuY2gTtC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_listPerson_to_particDesc(particDesc):\n",
        "    # listPerson to particDesc\n",
        "    listPerson = etree.Element('listPerson')\n",
        "    particDesc.append(listPerson)\n",
        "    return listPerson"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvA62ALpSEqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_textClass_to_profileDesc(profileDesc):\n",
        "    # textClass to profileDesc\n",
        "    textClass = etree.Element('textClass')\n",
        "    profileDesc.append(textClass)\n",
        "    return textClass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx47InaET89c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_keywords_to_textClass(textClass):\n",
        "    # keywords to textClass\n",
        "    keywords = etree.Element('keywords')\n",
        "    textClass.append(keywords)\n",
        "    return keywords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKf863F4UJ1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_term_to_keywords(keywords):\n",
        "    term = etree.Element('term', type='genreTitle', subtype='')\n",
        "    term.text = ''\n",
        "    keywords.append(term)\n",
        "    return term"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJk_vgY1gS1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_docTitle_to_front(front):\n",
        "    # docTitle to front\n",
        "    docTitle = etree.Element('docTitle')\n",
        "    front.append(docTitle)\n",
        "    return docTitle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCAZNVCpgS7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_titlePart_main_to_docTitle(docTitle, title):\n",
        "    # titlePart to docTitle\n",
        "    titlePart = etree.Element('titlePart', type='main')\n",
        "    titlePart.text = title.strip('\"')\n",
        "    docTitle.append(titlePart)\n",
        "    return titlePart"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vb_jKPIgoAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_titlePart_sub_to_docTitle(docTitle, title):\n",
        "    # titlePart to docTitle\n",
        "    titlePart = etree.Element('titlePart', type='sub')\n",
        "    titlePart.text = title\n",
        "    docTitle.append(titlePart)\n",
        "    return titlePart"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCk7bsjR6LHM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def inner_xml(element):\n",
        "    return (element.text or '') + ''.join(ET.tostring(e, 'unicode') for e in element)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP3I4bDyP7wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def replace_func(string):\n",
        "    for letter_with_umlaut, replacement in zip('äåöéè', 'aaoee'):\n",
        "        string = string.replace(letter_with_umlaut, replacement)\n",
        "    return string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li9JDY-qJrUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def recursive_clean(div):\n",
        "    if div.tag == 'epilogue':\n",
        "        if prefix + 'id' in div.attrib:\n",
        "            del div.attrib[prefix + 'id']\n",
        "    if div.tag == 'sp' and 'who' in div.attrib:\n",
        "        tmp = ['#' + elem[1 + 2 * (elem.startswith('#sp')):] for elem in div.attrib['who'].split()]\n",
        "        for i, elem in enumerate(tmp):\n",
        "            tmp[i] = re.sub(r'([A-ZÅÄÖ][a-zåäö]+)(?=[A-ZÅÄÖ])', r'\\1 ', elem[1:]) #.lower()\n",
        "            tmp[i] = '#' + tmp[i].replace(' ', '_')\n",
        "        div.attrib['who'] = replace_func(' '.join(tmp))\n",
        "    for tag in div.getchildren():\n",
        "        recursive_clean(tag)\n",
        "    if div.text:\n",
        "        div.text = re.sub(r'\\s{2,}', ' ', div.text).strip()\n",
        "        div.text = re.sub('\\n', ' ', div.text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LXu9-ZO0Wx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "authors_to_wikidata_urls = {}\n",
        "plays_to_wikidata_urls = {}\n",
        "\n",
        "with open('/content/drive/My Drive/SweDraCor_authors_Wikidata_ids.csv', 'r', encoding='utf-8') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    next(reader, None) # skip header\n",
        "    for row in reader:\n",
        "        authors_to_wikidata_urls[row[0]] = row[1]\n",
        "\n",
        "with open('/content/drive/My Drive/SweDraCor_plays_Wikidata_ids.csv', 'r', encoding='utf-8') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    next(reader, None) # skip header\n",
        "    for row in reader:\n",
        "        plays_to_wikidata_urls[row[1]] = row[3]\n",
        "\n",
        "def process_root(root):\n",
        "    teiHeader, text = root.getchildren()\n",
        "    fileDesc, encodingDesc, profileDesc = teiHeader.getchildren()\n",
        "    try:\n",
        "        titleStmt, publicationStmt, sourceDesc = fileDesc.getchildren()\n",
        "    except ValueError:\n",
        "        titleStmt, editionStmt, publicationStmt, sourceDesc = fileDesc.getchildren()\n",
        "        # NB: <edition>eDrama</edition>\n",
        "        fileDesc.remove(editionStmt)\n",
        "\n",
        "    titleStmt_children = titleStmt.getchildren()\n",
        "\n",
        "    sub_title = None\n",
        "    if titleStmt_children[1].tag == 'title':\n",
        "        # there is a sub-title\n",
        "        if titleStmt_children[2].tag == 'title':\n",
        "            main_title, sub_title, sub_title_two, author, *others = titleStmt_children\n",
        "            sub_title.text += ' (' + sub_title_two.text + ')'\n",
        "        else:\n",
        "            main_title, sub_title, author, *others = titleStmt_children\n",
        "    else:\n",
        "        # there is no sub-title\n",
        "        main_title, author, *others = titleStmt_children\n",
        "\n",
        "    # add xml:lang attribute to the title(s):\n",
        "    main_title.set(prefix + \"lang\", \"sv\")\n",
        "    if main_title.text is not None:\n",
        "        main_title.text = main_title.text.strip('\"')\n",
        "    if sub_title is not None:\n",
        "        sub_title.set(prefix + \"lang\", \"sv\")\n",
        "\n",
        "    # add translations (English) of titles to the 'titleStmt':\n",
        "    main_title_en = etree.Element('title', type='main')\n",
        "\n",
        "    # set xml:lang\n",
        "    main_title_en.set(prefix + \"lang\", \"en\")\n",
        "\n",
        "    main_title_text = main_title.text\n",
        "    if main_title_text is None:\n",
        "        main_title_text = ''\n",
        "        for iter_main_title in main_title.itertext():\n",
        "            main_title_text += iter_main_title.strip() + ' '\n",
        "        main_title_text = main_title_text.strip()\n",
        "    en_translation = translator.translate(main_title_text, src='sv', dest='en').text\n",
        "        \n",
        "    # capitalize non-functional words\n",
        "    main_title_en.text = titlecase(en_translation).strip().strip('\"')\n",
        "    # insert after main_title on swedish\n",
        "    main_title.addnext(main_title_en)\n",
        "\n",
        "    if sub_title is not None:\n",
        "        sub_title_en = etree.Element('title', type='sub')\n",
        "\n",
        "        # set xml:lang\n",
        "        sub_title_en.set(prefix + \"lang\", \"en\")\n",
        "\n",
        "        en_translation = translator.translate(sub_title.text, src='sv', dest='en').text\n",
        "        # capitalize non-functional words\n",
        "        sub_title_en.text = titlecase(en_translation).strip()\n",
        "        # insert after sub_title on swedish\n",
        "        sub_title.addnext(sub_title_en)\n",
        "\n",
        "    forename, nameLink, surname = [None] * 3\n",
        "    for child in author.getchildren()[0].getchildren():\n",
        "        if child.tag == 'forename':\n",
        "            forename = child.text\n",
        "        elif child.tag == 'nameLink':\n",
        "            nameLink = child.text\n",
        "        elif child.tag == 'surname':\n",
        "            surname = child.text\n",
        "\n",
        "    name = ''\n",
        "    if forename is not None:\n",
        "        name += forename + ' '\n",
        "    if nameLink is not None:\n",
        "        name += nameLink + ' '\n",
        "    if surname is not None:\n",
        "        name += surname\n",
        "    name = name.strip()\n",
        "    if not name:\n",
        "        name = author.getchildren()[0].text\n",
        "        forename, surname = name.split()\n",
        "\n",
        "    # NB: remove xml:id\n",
        "    if prefix + 'id' in author.attrib:\n",
        "        del author.attrib[prefix + 'id']\n",
        "    # add key\n",
        "    author.set('key', 'wikidata:' + authors_to_wikidata_urls[name].split('/')[-1])\n",
        "\n",
        "    # NB: delete reference information (sponsors/funders/editors/principals/encoders)\n",
        "    for other in others:\n",
        "        titleStmt.remove(other)\n",
        "\n",
        "    publisher, address, first_idno, second_idno, availability = publicationStmt.getchildren()\n",
        "\n",
        "    publisher.text = 'DraCor'\n",
        "    publisher.set(prefix + \"id\", \"dracor\")\n",
        "\n",
        "    # remove address\n",
        "    publicationStmt.remove(address)\n",
        "\n",
        "    first_idno.set('type', 'URL')\n",
        "    first_idno.text = 'https://dracor.org'\n",
        "\n",
        "    second_idno.set(prefix + \"base\", \"https://dracor.org/id/\")\n",
        "\n",
        "    del availability.attrib['status']\n",
        "    \n",
        "    licence = availability.getchildren()[0]\n",
        "    del licence.attrib['target']\n",
        "    for child in licence.getchildren():\n",
        "        licence.remove(child)\n",
        "\n",
        "    ab = etree.Element('ab')\n",
        "    ab.text = 'CC0'\n",
        "    licence.append(ab)\n",
        "\n",
        "    ref = etree.Element('ref', target='https://creativecommons.org/publicdomain/zero/1.0/')\n",
        "    ref.text = 'Licence'\n",
        "    licence.append(ref)\n",
        "\n",
        "    idno = etree.Element('idno', type='wikidata')\n",
        "    idno.set(prefix + \"base\", \"https://www.wikidata.org/entity/\")\n",
        "    idno.text = plays_to_wikidata_urls[main_title_text.strip('\"')].split('/')[-1]\n",
        "    publicationStmt.append(idno)\n",
        "\n",
        "    biblStruct = sourceDesc.getchildren()[0]\n",
        "\n",
        "    sourceDesc.remove(biblStruct)\n",
        "\n",
        "    if biblStruct.tag == 'listBibl':\n",
        "        # NB: listBibl\n",
        "        print(\"listBibl here\")\n",
        "        biblStruct = biblStruct.getchildren()[0]\n",
        "\n",
        "    biblStruct_children = biblStruct.getchildren()\n",
        "    monogr = None\n",
        "    for biblStruct_child in biblStruct_children:\n",
        "        if biblStruct_child.tag == 'monogr':\n",
        "            monogr = biblStruct_child\n",
        "            break\n",
        "\n",
        "    titles, idno, imprint = [None] * 3\n",
        "\n",
        "    for monogr_child in monogr.getchildren():\n",
        "        if monogr_child.tag == 'title':\n",
        "            if titles is None:\n",
        "                titles = []\n",
        "            titles.append(monogr_child)\n",
        "        elif monogr_child.tag == 'idno':\n",
        "            idno = monogr_child\n",
        "        elif monogr_child.tag == 'imprint':\n",
        "            imprint = monogr_child\n",
        "\n",
        "    if titles[0].text is None and titles[0][-1].tag == 'idno':\n",
        "        idno = titles[0][-1]\n",
        "        titles = titles[0][:-1]\n",
        "\n",
        "    url = idno.text\n",
        "\n",
        "    pubPlace, publisher, date, biblScopes, respStmt = [None] * 5\n",
        "    for imprint_child in imprint.getchildren():\n",
        "        if imprint_child.tag == 'pubPlace':\n",
        "            pubPlace = imprint_child\n",
        "        elif imprint_child.tag == 'publisher':\n",
        "            publisher = imprint_child\n",
        "        elif imprint_child.tag == 'date':\n",
        "            date = imprint_child\n",
        "        elif imprint_child.tag == 'biblScope':\n",
        "            if biblScopes is None:\n",
        "                biblScopes = []\n",
        "            biblScopes.append(imprint_child)\n",
        "        elif imprint_child.tag == 'respStmt':\n",
        "            respStmt = imprint_child\n",
        "        else:\n",
        "          \n",
        "#             raise ValueError(\"WHAT?\")\n",
        "            pass\n",
        "\n",
        "    when = None\n",
        "    if date is not None:\n",
        "        when = date.attrib['when']\n",
        "\n",
        "    bibl = etree.Element('bibl', type='digitalSource')\n",
        "    sourceDesc.append(bibl)\n",
        "    \n",
        "    for title in titles:\n",
        "        bibl.append(title)\n",
        "\n",
        "#     name = etree.Element('name')\n",
        "#     name.text = ''\n",
        "#     bibl.append(name)\n",
        "\n",
        "    idno = etree.Element('idno', type='URL')\n",
        "    idno.text = url\n",
        "    bibl.append(idno)\n",
        "\n",
        "    availability = etree.Element('availability', status='free')\n",
        "    p = etree.Element('p')\n",
        "    p.text = 'In the public domain.'\n",
        "    availability.append(p)\n",
        "    bibl.append(availability)\n",
        "\n",
        "    inner_bibl = etree.Element('bibl', type='originalSource')\n",
        "    bibl.append(inner_bibl)\n",
        "\n",
        "    for imprint_child in imprint.getchildren():\n",
        "        bibl.append(imprint_child)\n",
        "\n",
        "    date = etree.Element('date', type='print', when=when)\n",
        "    date.text = '\"' + when + '\"' + ' ' + '(' + url + ')'\n",
        "    inner_bibl.append(date)\n",
        "\n",
        "    date = etree.Element('date', type='premiere')\n",
        "    inner_bibl.append(date)\n",
        "\n",
        "    date = etree.Element('date', type='written')\n",
        "    inner_bibl.append(date)\n",
        "\n",
        "    # NB: remove encodingDesc\n",
        "    # teiHeader.remove(encodingDesc)\n",
        "    \n",
        "#     for child in profileDesc:\n",
        "#         profileDesc.remove(child)\n",
        "\n",
        "    particDesc = add_particDesc_to_profileDesc(profileDesc)\n",
        "    listPerson = add_listPerson_to_particDesc(particDesc)\n",
        "    textClass = add_textClass_to_profileDesc(profileDesc)\n",
        "    keywords = add_keywords_to_textClass(textClass)\n",
        "    term = add_term_to_keywords(keywords)\n",
        "    # revisionDesc\n",
        "    revisionDesc = etree.Element('revisionDesc')\n",
        "    teiHeader.append(revisionDesc)\n",
        "    listChange = etree.Element('listChange')\n",
        "    revisionDesc.append(listChange)\n",
        "    change = etree.Element('change', when=datetime.datetime.now().strftime(\"%Y-%m-%d\"))\n",
        "    change.text = \"(%s) convert from source\" % ('eg') # replace if necessary\n",
        "    listChange.append(change)\n",
        "\n",
        "    # delete xml:id attribute of text\n",
        "    del text.attrib[prefix + 'id']\n",
        "\n",
        "    # text children\n",
        "    front = None\n",
        "    try:\n",
        "        anchor, front, body, back, anchor, *comments = text.getchildren()\n",
        "    except ValueError:\n",
        "        anchor, body, back, anchor = text.getchildren()\n",
        "        if anchor.tag != 'anchor':\n",
        "            anchor, front, body, back = text.getchildren()\n",
        "\n",
        "    if back.getchildren()[0].tag == 'epilogue':\n",
        "        body.append(back.getchildren()[0])    \n",
        "    \n",
        "    try:\n",
        "        if front is not None:\n",
        "            castList = front.getchildren()[-1]\n",
        "        else:\n",
        "            raise ValueError('No front tag')\n",
        "\n",
        "        while castList.tag != 'castList':\n",
        "            body.insert(0, castList)\n",
        "            castList = front.getchildren()[-1]\n",
        "                \n",
        "            # append castList to body\n",
        "        body.insert(0, castList)\n",
        "    except (ValueError, IndexError):\n",
        "        castList = None\n",
        "\n",
        "    if front is not None:\n",
        "        docTitle = add_docTitle_to_front(front)\n",
        "        add_titlePart_main_to_docTitle(docTitle, main_title_text)\n",
        "\n",
        "    if sub_title is not None and front is not None:\n",
        "        add_titlePart_sub_to_docTitle(docTitle, sub_title.text)\n",
        "\n",
        "    byline = None\n",
        "    try:\n",
        "        *divs, byline = body.getchildren()\n",
        "        assert divs and byline.tag == 'byline'\n",
        "    except (ValueError, AssertionError):\n",
        "        byline = None\n",
        "        divs = body.getchildren()\n",
        "\n",
        "    for div in divs:\n",
        "        recursive_clean(div)\n",
        "\n",
        "    for sp in root.xpath('//sp'):\n",
        "        if 'who' not in sp.attrib:\n",
        "            continue\n",
        "        tmp = ['#' + elem[1 + 2 * (elem.startswith('#sp')):] for elem in sp.attrib['who'].split()]\n",
        "        for i, elem in enumerate(tmp):\n",
        "            tmp[i] = re.sub(r'([A-ZÅÄÖ][a-zåäö]+)(?=[A-ZÅÄÖ])', r'\\1 ', elem[1:]).lower()\n",
        "            tmp[i] = '#' + tmp[i].replace(' ', '_')\n",
        "        sp.attrib['who'] = replace_func(' '.join(tmp))\n",
        "\n",
        "    if byline is not None:\n",
        "        date = byline.getchildren()[0]\n",
        "        if re.fullmatch(r'[0-9]{4,4}', date.text) is not None:\n",
        "            written_date = bibl.getchildren()[-1].getchildren()[-1]\n",
        "            written_date.set('when', date.text)\n",
        "            written_date.text = date.text\n",
        "\n",
        "    tmp_ind = 1\n",
        "    while back.getchildren()[len(back.getchildren()) - tmp_ind].tag != 'div':\n",
        "        tmp_ind += 1\n",
        "    div = back.getchildren()[len(back.getchildren()) - tmp_ind]\n",
        "\n",
        "    try:\n",
        "        tmp_listPerson, listOrg, *_ = div.getchildren()\n",
        "        if tmp_listPerson.tag != 'listPerson':\n",
        "            comment, tmp_listPerson, listOrg, *_ = div.getchildren()\n",
        "    except ValueError:\n",
        "        tmp_listPerson, = div.getchildren()\n",
        "        if tmp_listPerson.tag != 'listPerson':\n",
        "            comment, tmp_listPerson, = div.getchildren()\n",
        "\n",
        "    if 'type' in tmp_listPerson.attrib:\n",
        "        tmp_listPerson = div\n",
        "\n",
        "    noncast_listPerson = None\n",
        "    try:\n",
        "        cast_listPerson, noncast_listPerson, *_ = tmp_listPerson.getchildren()\n",
        "        if 'type' in noncast_listPerson and noncast_listPerson.attrib['type'] == 'cast':\n",
        "            raise ValueError\n",
        "    except ValueError:\n",
        "        cast_listPerson_epilogue, cast_listPerson_main, *_ = tmp_listPerson.getchildren()\n",
        "        cast_listPerson = etree.Element('listPerson')\n",
        "        for inner_listPerson in [cast_listPerson_epilogue, cast_listPerson_main]:\n",
        "            for child in inner_listPerson:\n",
        "                cast_listPerson.append(child)\n",
        "\n",
        "    list_of_speakers = []\n",
        "    set_of_speakers = set()\n",
        "    for sp in root.xpath('//sp'):\n",
        "        if 'who' not in sp.attrib:\n",
        "            continue\n",
        "        whos = sp.attrib['who'].split()\n",
        "        for who in whos:\n",
        "            if who not in set_of_speakers:\n",
        "                set_of_speakers.add(who)\n",
        "                list_of_speakers.append(who)\n",
        "\n",
        "    list_of_speakers = [re.sub(r'sp([A-Z].*)', r'\\1', elem[1:]) for elem in list_of_speakers]\n",
        "\n",
        "    xml_id_to_sex = {}\n",
        "    xml_id_to_fullname = {}\n",
        "    xml_id_to_type_of_person = {}\n",
        "\n",
        "    for type_listPerson in [cast_listPerson, noncast_listPerson]:\n",
        "        for child in type_listPerson.getchildren():\n",
        "            if child.tag in ['person', 'personGrp', 'listPerson']:\n",
        "                if child.tag == 'listPerson':\n",
        "                    childs = child.getchildren()\n",
        "                else:\n",
        "                    childs = [child]\n",
        "                for child in childs:\n",
        "                    if child.tag == 'listPerson':\n",
        "                        inner_children = child.getchildren()\n",
        "                    else:\n",
        "                        inner_children = [child]\n",
        "                    for inner_child in inner_children:\n",
        "                        if prefix + 'id' not in inner_child.attrib:\n",
        "                            continue\n",
        "                        xml_id = inner_child.attrib[prefix + 'id']\n",
        "                        xml_id = re.sub(r'([A-ZÅÄÖ][a-zåäö]+)(?=[A-ZÅÄÖ])', r'\\1 ', xml_id).lower()\n",
        "                        xml_id = xml_id.replace(' ', '_')\n",
        "                        xml_id = replace_func(xml_id)\n",
        "                        if xml_id in list_of_speakers:\n",
        "                            if inner_child.tag == 'person':\n",
        "                                xml_id_to_type_of_person[xml_id] = 'person'\n",
        "                            else:\n",
        "                                xml_id_to_type_of_person[xml_id] = 'personGrp'\n",
        "                            if 'sex' not in inner_child.attrib:\n",
        "                                xml_id_to_sex[xml_id] = 'UNKNOWN'\n",
        "                            else:\n",
        "                                xml_id_to_sex[xml_id] = inner_child.attrib['sex'].upper()\n",
        "                            try:\n",
        "                                persName, *_ = inner_child.getchildren()\n",
        "                                if persName.tag not in ['person', 'personGrp', 'occupation', 'persName', 'note', 'age']:\n",
        "                                    comment, persName, *_ = inner_child.getchildren()\n",
        "                            except ValueError:\n",
        "                                xml_id_to_fullname[xml_id] = ' '.join([elem.capitalize() for elem in xml_id.split('_')])\n",
        "                                continue\n",
        "                            full_text = ''\n",
        "                            try:\n",
        "                                tmp = deepcopy(inner_child)\n",
        "                                for comment in tmp.xpath('//comment()'):\n",
        "                                    comment_parent = comment.getparent()\n",
        "                                    comment_parent.remove(comment)\n",
        "                                for child in tmp.getchildren():  # persName\n",
        "                                    if child.text is not None:\n",
        "                                        if re.sub(r'\\s{2,}', ' ', child.text):\n",
        "                                            full_text += re.sub(r'\\s{2,}', ' ', child.text).strip() + ', '\n",
        "                                    else:\n",
        "                                        was_text = ''\n",
        "                                        for part_of_text in child.itertext():\n",
        "                                            full_text += re.sub(r'\\s{2,}', ' ', part_of_text).strip() + ' '\n",
        "                                            was_text += re.sub(r'\\s{2,}', ' ', part_of_text).strip()\n",
        "                                        full_text = full_text.strip()\n",
        "                                        if was_text:\n",
        "                                            full_text += ', '\n",
        "                            except ValueError:\n",
        "                                continue\n",
        "                #             full_text = inner_xml(persName)\n",
        "                            full_text = full_text.strip(' ,')\n",
        "                            xml_id_to_fullname[xml_id] = re.sub(r'\\s{2,}', r' ', full_text)\n",
        "\n",
        "    # NB: here\n",
        "    print(set(list_of_speakers) ^ set(xml_id_to_sex.keys()), set(list_of_speakers) ^ set(xml_id_to_fullname.keys()), set(list_of_speakers) ^ set(xml_id_to_type_of_person.keys()))\n",
        "    print(set(list_of_speakers) - set(xml_id_to_sex.keys()), set(list_of_speakers) - set(xml_id_to_fullname.keys()), set(list_of_speakers) - set(xml_id_to_type_of_person.keys()))\n",
        "    \n",
        "    for xml_id in list_of_speakers:\n",
        "        if xml_id_to_type_of_person[xml_id] == 'person':\n",
        "            person = etree.Element('person')\n",
        "            person.set(prefix + \"id\", xml_id)\n",
        "            person.set('sex', xml_id_to_sex[xml_id])\n",
        "            persName = etree.Element('persName')\n",
        "            persName.text = xml_id_to_fullname[xml_id]\n",
        "            person.append(persName)\n",
        "            listPerson.append(person)\n",
        "        else:\n",
        "            personGrp = etree.Element('personGrp')\n",
        "            personGrp.set(prefix + \"id\", xml_id)\n",
        "            personGrp.set('sex', xml_id_to_sex[xml_id])\n",
        "            name = etree.Element('name')\n",
        "            name.text = xml_id_to_fullname[xml_id]\n",
        "            personGrp.append(name)\n",
        "            listPerson.append(personGrp)\n",
        "\n",
        "    for stage in text.xpath('//stage'):\n",
        "        if 'who' in stage.attrib:\n",
        "            stage.attrib['who'] = replace_func(stage.attrib['who'].lower())\n",
        "\n",
        "    if sub_title is not None:\n",
        "        if sub_title_en.text.split()[0].lower() in ['comedy', 'drama', 'tragedy']:\n",
        "            term.attrib['subtype'] = sub_title_en.text.split()[0].lower()\n",
        "            term.text = '\"' + sub_title.text + '\"'\n",
        "\n",
        "    result = etree.tostring(root.getroottree(), pretty_print=True, xml_declaration=True, encoding=\"UTF-8\").decode('utf-8')\n",
        "    result = html_.unescape(result)\n",
        "#     result = re.sub(r'<fw type=\"pageNum\">([0-9]+)</fw>', r'<pb n=\"\\1\"/>', result)\n",
        "    result = re.sub(r'([^\\s])(<[^/])', r'\\1 \\2', result)\n",
        "    for i in range(10):\n",
        "#         print(i)\n",
        "        result = re.sub(r'(<p(?: rend=\\\"[^><]*?\\\")?>(?:(?!</p>).)*?)\\s{2,}((?:(?!</p>).)*?</p>)', r'\\1 \\2', result, 0, re.DOTALL)\n",
        "\n",
        "    result = re.sub(r'(</[^>]+>) (</[^>]+>)', r'\\1\\2', result)\n",
        "    result = re.sub(r'/>([^\\s])', r'/> \\1', result)\n",
        "    result = re.sub(r'\\s+</stage>', r'</stage>', result)\n",
        "    result = re.sub(r'\\( <', r'(<', result)\n",
        "    result = re.sub(r',([^\\s])', r', \\1', result)\n",
        "    result = re.sub(r' ([,):])', r'\\1', result)\n",
        "    result = re.sub(r'([(]) ', r'\\1', result)\n",
        "    result = re.sub(r'\\s+([^<\\s])', r' \\1', result)\n",
        "    result = re.sub(r' (</)', r'\\1', result)\n",
        "    result = re.sub(r'(<[^/][^<>]*?>) <', r'\\1<', result)\n",
        "    result = re.sub(r' \\.', '.', result)\n",
        "    result = re.sub(r'- (<pb [^<>]*?/>) ', r'-\\1', result)\n",
        "    \n",
        "    result = re.sub(r'\\n\\s+([^><]*?)</stage>', r' \\1</stage>', result)\n",
        "    with open('/content/drive/My Drive/swedracor/converted_plays/' + replace_func(surname.lower() + '-' + '-'.join(main_title_text.lower().split()).split('/')[-1]) + '.xml', 'w', encoding='utf-8') as f:\n",
        "        f.write(result)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imqxn9a8a8ou",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "adbf5238-3fb2-4b21-9c4b-c159cd27f920"
      },
      "source": [
        "for file in \"\"\"AgrellA-Domd.xml                                    LefflerAC-HurManGorGodt.xml       StrindbergA-InforDoden.xml\n",
        "AgrellA-EnHufvudsak.xml                             LefflerAC-MosterMalvina.xml       StrindbergA-Kamraterna.xml\n",
        "AgrellA-EnLektion.xml                               LefflerAC-SannaKvinnor.xml        StrindbergA-Lycko-PersResa.xml\n",
        "AgrellA-Ensam.xml                                   LefflerAC-Skadespelerskan.xml     StrindbergA-Marodorer.xml\n",
        "AgrellA-Hvarfor.xml                                 LefflerAC-UnderToffeln.xml        StrindbergA-MasterOlof.xml\n",
        "AgrellA-IngridEnDodsKarlekssaga.xml                 LindheW-Modrar.xml                StrindbergA-Moderskarlek.xml\n",
        "AgrellA-Smastadslif.xml                             LundbergE-ForlatMig.xml           StrindbergA-Paria.xml\n",
        "AureliusH-FarmorsFodelsedag.xml                     MallingM-FruLeonora.xml           StrindbergA-Samum.xml\n",
        "BarthelsonA-Efterspel.xml                           MarholmL-Otteringning.xml         StrindbergA-TillDamaskus.xml\n",
        "BenedictssonV-Final.xml                             MeyersonG-DenNyaKlassen.xml       TopeliusT-ISmaMaffarnasLand.xml\n",
        "BenedictssonV-ITelefon.xml                          MeyersonG-EttPojkstreck.xml       TopeliusT-JeppeOchMurra.xml\n",
        "BenedictssonV-RomeosJulia.xml                       MolanderH-Varflod.xml             TopeliusZ-Askungen.xml\n",
        "BremerF-KonstnarnsFortviflan.xml                    StrindbergA-AnnoFyrtiatta.xml     TopeliusZ-JennysFormaningar.xml\n",
        "GeijerstamG-LarsAndersOchJanAndersOchDerasBarn.xml  StrindbergA-Bandet.xml            TopeliusZ-Krypskyttarne.xml\n",
        "HedbergF-Rospiggarna.xml                            StrindbergA-DenStarkare.xml       TopeliusZ-LuciasZiffror.xml\n",
        "IndebetouH-IDetGrona.xml                            StrindbergA-Fadren.xml            TopeliusZ-Perdita.xml\n",
        "IndebetouH-IFruntimmersveckan.xml                   StrindbergA-Fordringsegare.xml    TopeliusZ-Skogskonungen.xml\n",
        "KullgrenL-Karlek.xml                                StrindbergA-ForstaVarningen.xml   TopeliusZ-Snurran.xml\n",
        "KuylenstiernaE-NarNyarKom.xml                       StrindbergA-FrokenJulie.xml       TopeliusZ-StationSylvester.xml\n",
        "KuylenstiernaE-NuArDetJulIgen.xml                   StrindbergA-GilletsHemlighet.xml  TopeliusZ-TidernasSpegel.xml\n",
        "LefflerAC-Elfvan.xml                                StrindbergA-HerrBengtsHustru.xml  WahlenbergA-PaVakt.xml\n",
        "LefflerAC-Familjelycka.xml                          StrindbergA-Hostslask.xml         WahlenbergA-TvaValsprak.xml\"\"\".split():\n",
        "    # tmp\n",
        "    # file = 'StrindbergA-MasterOlof.xml'\n",
        "    with open('/content/drive/My Drive/swedracor/' + file, 'r', encoding='utf-8') as f:\n",
        "        print(file)\n",
        "        xml = preprocess_xml(f.read())\n",
        "        root = get_root(xml)\n",
        "        \n",
        "        # strip all namespaces\n",
        "        for tag in root.iter():\n",
        "            try:\n",
        "                if '}' in tag.tag:\n",
        "                    tag.tag = tag.tag.split('}', 1)[1]\n",
        "            except TypeError:\n",
        "                continue\n",
        "\n",
        "        # add 'xml-stylesheet' tag and set lang in TEI tag:\n",
        "        root.addprevious(etree.PI('xml-stylesheet', 'type=\"text/css\" href=\"../css/tei.css\"'))\n",
        "        root.set(prefix + \"lang\", \"sv\")\n",
        "\n",
        "        process_root(root)"
      ],
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AgrellA-Domd.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "LefflerAC-HurManGorGodt.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-InforDoden.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "AgrellA-EnHufvudsak.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "LefflerAC-MosterMalvina.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-Kamraterna.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "AgrellA-EnLektion.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "LefflerAC-SannaKvinnor.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-Lycko-PersResa.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "AgrellA-Ensam.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "LefflerAC-Skadespelerskan.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-Marodorer.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "AgrellA-Hvarfor.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "LefflerAC-UnderToffeln.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-MasterOlof.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "AgrellA-IngridEnDodsKarlekssaga.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "LindheW-Modrar.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-Moderskarlek.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "AgrellA-Smastadslif.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "LundbergE-ForlatMig.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-Paria.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "AureliusH-FarmorsFodelsedag.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "MallingM-FruLeonora.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-Samum.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "BarthelsonA-Efterspel.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "MarholmL-Otteringning.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-TillDamaskus.xml\n",
            "listBibl here\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "BenedictssonV-Final.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "MeyersonG-DenNyaKlassen.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "TopeliusT-ISmaMaffarnasLand.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "BenedictssonV-ITelefon.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "MeyersonG-EttPojkstreck.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "TopeliusT-JeppeOchMurra.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "BenedictssonV-RomeosJulia.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "MolanderH-Varflod.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "TopeliusZ-Askungen.xml\n",
            "listBibl here\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "BremerF-KonstnarnsFortviflan.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-AnnoFyrtiatta.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "TopeliusZ-JennysFormaningar.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "GeijerstamG-LarsAndersOchJanAndersOchDerasBarn.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-Bandet.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "TopeliusZ-Krypskyttarne.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "HedbergF-Rospiggarna.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-DenStarkare.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "TopeliusZ-LuciasZiffror.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "IndebetouH-IDetGrona.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-Fadren.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "TopeliusZ-Perdita.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "IndebetouH-IFruntimmersveckan.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-Fordringsegare.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "TopeliusZ-Skogskonungen.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "KullgrenL-Karlek.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-ForstaVarningen.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "TopeliusZ-Snurran.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "KuylenstiernaE-NarNyarKom.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-FrokenJulie.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "TopeliusZ-StationSylvester.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "KuylenstiernaE-NuArDetJulIgen.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-GilletsHemlighet.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "TopeliusZ-TidernasSpegel.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "LefflerAC-Elfvan.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-HerrBengtsHustru.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "WahlenbergA-PaVakt.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "LefflerAC-Familjelycka.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "StrindbergA-Hostslask.xml\n",
            "set() set() set()\n",
            "set() set() set()\n",
            "WahlenbergA-TvaValsprak.xml\n",
            "set() set() set()\n",
            "set() set() set()\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}